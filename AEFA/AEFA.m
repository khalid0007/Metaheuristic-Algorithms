function [selectedFeatures, initialPerformance, finalPerformance] = AEFA(trainFeatures, trainLabels, testFeatures, testLabels)
% Feature selection using AEFA
% Paper : "AEFA : Artificial electrical field algorithm for Global Optimization"
% Author : Anita & Anupam Yadav

% ========<Steps Of Artificial Electrical Field Algorithm>===========
% Step 1: Intialise the population
% Step 2: Calculate charge for each in agent in population
% Step 3: Calculate complete electric field for each charge
% Step 4: Update velocity
% Step 5: Update position of charged agents
% Step 6: If breaking condition is not met continue from step 2
% Step 7: Best fitness value is considered as the optimal solution
% generated by the metaheuristic algo
% <================================================================>

% Code Author: Khalid Hassan Sheikh
% BCSE, Jadavpur University (2018-2022)

% ========================<INITIALISATION OF VARIABLE>=======================
featureLength = size(trainFeatures, 2);
populationSize = 30;
% X is the d-plane position of a perticular agent
X = zeros([populationSize, featureLength]);
% Position after each iteration
P = zeros([populationSize, featureLength]);
velocity = zeros([populationSize, featureLength]);
% Coulomb's constant after each iteration
K0 = 500;
K = K0;

% Fitness
currFitness = zeros([populationSize, 1]);
prevFitness = zeros([populationSize, 1]);

% Charge
charges = zeros([populationSize, 1]);

% Performance;
initialPerformance = 0.00;
finalPerformance  = 0.00;

maxIter = 150;
classifierName = "svm";
paramValue = 'polynomial';

% Intialise indivisuals
% initialPerformance = calFitness(trainFeatures, trainLabels, testFeatures, testLabels, ones([1, featureLength]), classifierName, paramValue);

% Number of features that should be selected intially for each agent
percentSelect = 0.25;

% s function, vs function, a function, x function
X(1, :) = ones([1, featureLength]);
P(1, :) = ones([1, featureLength]);

% Intialisation of 
for i = 2:populationSize
    for j = 1:ceil(percentSelect*featureLength)
        randomIndex = mod(randi(1000000*i), featureLength) + 1;
        X(i, randomIndex) = 1;
        P(i, randomIndex) = 1;
    end
end

currFitness = calFitness(trainFeatures, trainLabels, testFeatures, testLabels, X, classifierName, paramValue);
prevFitness = currFitness;

initialPerformance = modifiedClassify(trainFeatures, trainLabels, testFeatures, testLabels, P(1, :), classifierName, paramValue);
finalPerformance = initialPerformance; 
bestFitness = 0.00;
bestIndx = 0;
alpha = 10;
    
for iteration = 1:maxIter
    clc;
    fprintf("Iteration: %d, Final Accuracy: %f, Initial Accuracy: %f\n", iteration, finalPerformance, initialPerformance);
    % Calculate charge from last updated fitness
    K = K0*exp(alpha*-1*(iteration/maxIter));
    charges = calCharges(prevFitness);
    velocity = rand()*velocity + calEF(X, P, charges, K);
    temp = (2*X - 1) + velocity;
    X = SFunction(temp);
    currFitness = calFitness(trainFeatures, trainLabels, testFeatures, testLabels, X, classifierName, paramValue);
    
    for j = 1:populationSize
        if currFitness(j,1) > prevFitness(j, 1)
            prevFitness(j, 1) = currFitness(j,1);
            P(j, :) = X(j, :);
        end
        
        if bestFitness < prevFitness(j, 1)
            bestFitness = prevFitness(j, 1);
            bestIndx = j;
        end
    end
    
    finalPerformance = modifiedClassify(trainFeatures, trainLabels, testFeatures, testLabels, P(bestIndx, :), classifierName, paramValue);
end

selectedFeatures = P(bestIndx, :);

end

function [accuracy] = modifiedClassify(trainFeatures, trainLabels, testFeatures, testLabels, agent, classifierName, paramValue)
accuracy = 0.00;

if classifierName == "svm"
    accuracy = SVC(trainFeatures, trainLabels, testFeatures, testLabels, agent, paramValue);
elseif classifierName == "knn"
    accuracy = knnClassifier(trainFeatures, trainLabels, testFeatures, testLabels, agent, paramValue);
elseif classifierName == "rf"
    accuracy = RandomForest(trainFeatures, trainLabels, testFeatures, testLabels, agent, paramValue);
else
   fprintf("Wrong classifier name!\n"); 
end

end



function [T] = SFunction(X)
T = zeros(size(X));

for i = 1:size(X, 1)
    for j = 1:size(X, 2)
        temp = sigmoid(X(i, j), 0, 100000.00);
        if temp >= 0
            T(i,j) = 1;
        else
            T(i,j) = 0;
        end
    end
end

end


% Calculate the fitness value for each agent
function [fitness, accuracy] = calFitness(trainFeatures, trainLabels, testFeatures, testLabels, agents, classifierName, paramValue)
numAgents = size(agents, 1);
featureLength = size(agents, 2);
fitness = zeros([numAgents, 1]);

for i = 1:numAgents
   % Accuracy normalised in [0, 1]
   accuracy = modifiedClassify(trainFeatures, trainLabels, testFeatures, testLabels, agents(i, :), classifierName, paramValue);
   fitness(i) = 1.0*accuracy + 0.0*(1 - sum(agents(i, :))/featureLength);
end
end

function [charges] = calCharges(fitness)
% q(i) = exp((fitness(i) - worst)/(best - worst));
numAgents = size(fitness, 1);
charges = zeros([numAgents, 1]);

worst = 2.00;
best = 0.00;

for i = 1:numAgents
   if worst > fitness(i,1)
       worst = fitness(i,1);
   end
   if best < fitness(i,1)
       best = fitness(i,1);
   end
end

for i = 1:numAgents
    charges(i, 1) = exp((fitness(i,1) - worst)/(fitness(i,1) - best));
end

end


function [EF] = calEF(X, P, charges, K)
numAgents = size(X, 1);
featureLength = size(X, 2);
EF = zeros([numAgents, featureLength]);

for i = 1:numAgents
    for j = 1:numAgents
        if i == j
            continue;
        end
        EF(i, :) = EF(i, :) + (rand()*K*charges(i)*charges(j)/calDist(X(i, :), X(j, :))).*(P(j, :) - X(i, :));
    end
end

end

function [dist] = calDist(xi, xj)
    temp = (xi - xj);
    temp = temp.*temp;
    dist = sum(temp) + 0.0001;
end



